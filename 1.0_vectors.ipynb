{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectors & Spaces\n",
    "\n",
    "Vectors are fuindamental to Machine Learning, if you can build some insight into vectors, vector spaces and how to operate on them then understanding teh fundamentals of a lot of Machine Learning (ML) algortihms become a lot easier.\n",
    "\n",
    "You can begin to understand how things as disparate as `k-means clusters` and exotic `deep neural network` all relate to undamentally representing, transforming, slicing, dcing and measuring information content of vector spaces.\n",
    "\n",
    "So it's a good idea to start here, we'll try and do so with the minimum of maths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectors\n",
    "\n",
    "When working in a programming language we often think about vectors as lists and in some languages we have objects or classes that explicitly call themselves `vectors`. e.g. `std::vector` in the c++ standard library but even they don;'t provide an interface that aligns with a mathematical vector.\n",
    "\n",
    "In native javascript, the closest thing we have the the native Array which as a datastructure fits out needs for a vector but it does not provide any of teh mathematical operations that we need when treating it as a vector. We are going to develop some of our own here.\n",
    "\n",
    "Typically we will see maths like: \n",
    "\n",
    "\\begin{equation*}\n",
    "y = Wx + b\n",
    "\\end{equation*}\n",
    "\n",
    "where $y, x, b$ are assumed to be vectors and $W$ is a matrix, dots $\\dot{y}$ are sometimes also used to denote vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ 1, 3 ]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// We can easily contain a vector within an array\n",
    "x = [1, 3];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vector Spaces 1\n",
    "\n",
    "A vector space is mathematical concept that wis quite hard to grasp in general. A vector space in genreall defined by a dimension and an `inner product` which we will talk about below. \n",
    "\n",
    "We are lucky as in most of the time we work within a Euclidean Vector space, which is a space that we are used to and is applicable to the real world around us.\n",
    "\n",
    "When reading ML material we will see notation like $R^N$ representing an n-dimensional space, that is spanned by n-dimensional vectors. So $R^2$ simply means 2 dimensional, $R^3$ means 3D, and so on...\n",
    "\n",
    "Most of teh time when we see $R^N$ the author is talking about euclidean space and the defintions we go through below apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Magnitude (L2 norm)\n",
    "The length of a vector, or it's magnitude is given by the square root of the squared sum of its elements. Or $$\\Vert x \\Vert = \\sqrt{\\sum_{i=0}^N x^2}$$\n",
    "\n",
    "This is also known as the `L2 Norm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// simply for our 2 dimensional case\n",
    "var X1 = Math.sqrt(Math.pow(x[0], 2) + Math.pow(x[1], 2))\n",
    "console.log(X1)\n",
    "\n",
    "// more generally for anmy length vector\n",
    "var X2 = Math.sqrt(x.map(x => x*x).reduce((a,x) => a+x , 0))\n",
    "console.log(X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### L1 Norm\n",
    "\n",
    "There is an alternate measure of vector magnitude that you may encouter, the `L1 norm`. Which is simply the bum of the absolute components.\n",
    "\n",
    "$$\\vert x \\vert = \\sum_{i=0}^N \\vert x \\vert$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var X_L1 = x.reduce((a,x) => a + Math.abs(x), 0);\n",
    "console.log(X_L1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit Vectors\n",
    "\n",
    "Unit vectors $u$ are a vectors whose magnitude is 1.0, aka `unity`. There is no length information. All unit vectors start at the origin and end on the unit circle, sphere or hyper sphere depending on the dimensio. So unit vectors vary only in angle.\n",
    "\n",
    "$$\\hat x = \\frac{x}{\\Vert x \\Vert}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// compute a unit vector from any vector X just by dividing out by the magnitude\n",
    "var u = x.map(x => x/X1)\n",
    "console.log(\"unit vector\", u)\n",
    "\n",
    "// double chaeck the magnitude of u\n",
    "var U1 = Math.sqrt(u.map(x => x*x).reduce((a,x) => a+x , 0))\n",
    "console.log(\"expect unity\", U1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basis Vectors\n",
    "\n",
    "The basis of a vector space are the primary axes of that space. In $R^2$ the basis is represented by 2 unit vectors; $\\hat e_0, \\hat e_1$. This is the standard basis in cartesian space. \n",
    "\n",
    "We can see that this generalises well to $R^N$ where we have unit vectors $\\hat e_0, \\hat e_1, ... , \\hat e_{N-1}$ that are each all zeros.\n",
    "\n",
    "(Terminology Note! ML folks call a vector of zeros with a single component set to 1, [one hot](https://en.wikipedia.org/wiki/One-hot) and sometime specifically encode data into that representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// the standard basis of 2 dimensional space\n",
    "var e0 = [1, 0];\n",
    "var e1 = [0, 1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner products or the dot product\n",
    "\n",
    "The inner product of two vectors in cartesian space is defined as: $$a \\bullet b = \\Vert a \\Vert \\Vert b \\Vert cos(\\alpha) = \\sum_{i-0}^{N-1}a_i b_i$$\n",
    "\n",
    "so take the product of all vector components and sum them gemetrically this product is the product of the magnitude of the two vectors times the cosing of the angle between them. Not that intuitive.\n",
    "\n",
    "But there are some importanrt properties:\n",
    "\n",
    " - if two vectors are co-linear or parallel the $a \\bullet b = \\Vert a \\Vert \\Vert b \\Vert$\n",
    " - if two unit vectors are co-linear or parallel the $a \\bullet b = 1$\n",
    " - if two vectors are `orthogonal` then $a \\bullet b = 0$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var a = [ -1, 4 ];\n",
    "var b = [ 3, 2 ];\n",
    "\n",
    "var dot = 0;\n",
    "for (var i = 0; i < a.length; i++) {\n",
    "    dot = a[i]*b[i];\n",
    "}\n",
    "console.log(dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: what is the dot product of the standard basis in 2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// compute the dot product of e0 & e1 here, whatdo you expect it to be?\n",
    "// is there a better native way than a for loop?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Projections\n",
    "\n",
    "Something that the dot product also represents is a projection. Let's look at that equation again.\n",
    "\n",
    "$$a \\bullet b = \\Vert a \\Vert \\Vert b \\Vert cos(\\alpha) = \\sum_{i-0}^{N-1}a_i b_i$$\n",
    "\n",
    "so \n",
    "\n",
    "$$\\frac{a \\bullet b}{\\Vert b \\Vert} = \\Vert a \\Vert cos(\\alpha)$$\n",
    "\n",
    "or on other words, the dot product can be used to project the vector `a` onto `b` or vice versa.\n",
    "\n",
    "![dot product](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Dot_Product.svg/300px-Dot_Product.svg.png)\n",
    "[image: wikipedia](https://commons.wikimedia.org/wiki/File:Dot_Product.svg)\n",
    "\n",
    "this becomes more interesting when we replace be with the unit vector $$a \\bullet \\hat u = \\Vert a \\Vert cos(\\alpha)$$\n",
    "\n",
    "So we can project a vector along any direction by taking the dot product with another unit vector in that direction, as we will get a meaningful scalar value depending on teh angle between them.\n",
    "\n",
    "We can project a vector onto a given basis by taking the dot product with each of the basis vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var c = [ -3, 7 ];\n",
    "\n",
    "var c_proj = [\n",
    "    c[0]*e0[0] + c[0]*e1[0],\n",
    "    c[0]*e0[0] + c[0]*e1[0]\n",
    "];\n",
    "\n",
    "console.log(\"c projected onto e0, e1 equal\", c, \"c!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the standard basis is not that interesting, it's like an identity function and actually if we stack the vectors of the standard basis we get an identity matrix.\n",
    "\n",
    "$$\n",
    "I =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and the operation we just did above was $c = Ic$\n",
    "\n",
    "We can do more interesting operations with arbitrary matrices of course.\n",
    "\n",
    "Exercise: try computing $y = Rc$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var theta = 30/2*Math.PI;\n",
    "var r0 = [Math.cos(theta), -Math.sin(theta)], r1 = [Math.sin(theta), Math.cos(theta)]\n",
    "var R = [r0, r1]\n",
    "\n",
    "var y = 0; // write some code here, matrix math is awkward in native js!\n",
    "\n",
    "\n",
    "console.log(\"c projected onto R equals\", y, \"which is c rotated by 30 degrees\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    " - Machine Learning under the hood is fundamentally about dealing with vector and vector spaces\n",
    " - Information is represented in $R^N$ an n-dimensional spacewhere in practice N can become very large! 1000's of components\n",
    " - Bases are sets of vectors that represent the principal axes within a vector space. Bases are said to span the space. Basis are orthogonal of their inner products are mutually `0`\n",
    " - Inner products can be used to project vectors onto one another, or determine the contribution of a vector in any particular abitrary direction.\n",
    " - Inner products are a fundamental measure of `similarity` between a pair of vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better Tools\n",
    "\n",
    "Native javascript is very limited when it comes to the type of mathematical manipulations we need ot make at a low level. Solving that is beyond tehscope of this workshop, but if you do need to do some linear algegra at JS level and can live with teh performance then libraries like these are work looking at.\n",
    "\n",
    " - [Math.js](http://mathjs.org/)\n",
    " - [glMatrix](http://glmatrix.net/)\n",
    "\n",
    "However, bear in mind that any library that you use would need to be compatible with the ML library that you also want to use, and at the end of the day if you are trying to do ML it's best to find a high level library for the technique that you are interested in, which will hopefully be optimised to a level beyond that which a generic matrix library is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    " - [Vector spaces as moidels for Natural Language Processing (NLP)](https://en.wikipedia.org/wiki/Vector_space_model)\n",
    " - [facebook's hyperbolic space for heirarchical representations](https://medium.com/towards-data-science/facebook-research-just-published-an-awesome-paper-on-learning-hierarchical-representations-34e3d829ede7)\n",
    " - [Differences between the L1 & L2 norms](http://www.chioka.in/differences-between-the-l1-norm-and-the-l2-norm-least-absolute-deviations-and-least-squares/)\n",
    " \n",
    " - [Recommended reading on linear algebra](http://www.cs.cmu.edu/~zkolter/course/linalg/linalg_notes.pdf) from the book \"Machine Learning mit Python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "jp-Babel (Node.js)",
   "language": "babel",
   "name": "babel"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "8.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
